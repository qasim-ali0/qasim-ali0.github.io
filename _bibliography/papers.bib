@misc{ali2025humanoidworldmodelsopen,
      title={Humanoid World Models: Open World Foundation Models for Humanoid Robotics}, 
      author={Muhammad Qasim Ali and Aditya Sridhar and Shahbuland Matiana and Alex Wong and Mohammad Al-Sharman},
      year={2025},
      eprint={2506.01182},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2506.01182}, 
}

@misc{ali2025graphpadinferencetime3dscene,
      title={GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering}, 
      author={Muhammad Qasim Ali and Saeejith Nair and Alexander Wong and Yuchen Cui and Yuhao Chen},
      year={2025},
      eprint={2506.01174},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2506.01174}, 
}


@InProceedings{10.1007/978-3-031-81854-7_13,
  author="Ali, Qasim
  and Chen, Yuhao
  and Wong, Alex",
  editor="Ma, Jun
  and Zhou, Yuyin
  and Wang, Bo",
  title="RepViT-MedSAM: Efficient Segment Anything in the Medical Images",
  booktitle="Medical Image Segmentation Foundation Models. CVPR 2024 Challenge: Segment Anything in Medical Images on Laptop",
  year="2025",
  publisher="Springer Nature Switzerland",
  address="Cham",
  pages="195--205",
  abstract="Segmenting medical images to identify lesions, organs and other areas of interest is crucial for diagnosis and treatment decisions. Traditionally, segmentation is accomplished through manual tools or using automated task-specific neural network models. A promising alternative solution to this problem is to create general-purpose models for segment anything in medical images, such as MedSAM [8]. These foundation models can segment regions across a multitude of modalities, at levels comparable to task-specific models. However, these models are often large and computationally expensive, preventing them from being used in clinical settings where they lack dedicated GPUs. We propose an efficient model for the segment anything in medical images problem, RepViT-MedSAM, created from a two step training process. First, the image encoder of MedSAM is distilled into a more efficient RepViT feature detector using aggressively augmented medical images. Then the entire end-to-end model, with the prompt encoder and mask decoder, is fine-tuned using ground truth masks and MedSAM's predictions. On the test set, RepViT-MedSAM surpasses the performance of baseline MedSAM in performance and efficiency, achieving an average Dice Similarity Coefficient (DSC) of 0.8528, an average Normalized Surface Distance (NSD) of 0.8666, taking a total execution time of 195 s, and ranking 12/23 among other contestants. RepViT-SAM offers a promising solution for real-world medical image segmentation with its efficiency and accuracy. The code for this project is available at https://github.com/icecap360/TurboMedSAM.",
  isbn="978-3-031-81854-7"
}



@misc{hu2025mgsomonocularrealtimephotometric,
      title={MGSO: Monocular Real-time Photometric SLAM with Efficient 3D Gaussian Splatting}, 
      author={Yan Song Hu and Nicolas Abboud and Muhammad Qasim Ali and Adam Srebrnjak Yang and Imad Elhajj and Daniel Asmar and Yuhao Chen and John S. Zelek},
      year={2025},
      eprint={2409.13055},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2409.13055}, 
}---
---
@string{aps = {American Physical Society,}}
